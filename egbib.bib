
% @misc{Authors14,
%  author = {Authors},
%  title = {The frobnicatable foo filter},
%  note = {Face and Gesture  submission ID 324. Supplied as additional material {\tt fg324.pdf}},
%  year = 2014
% }

% @misc{Authors14b,
%  author = {Authors},
%  title = {Frobnication tutorial},
%  note = {Supplied as additional material {\tt tr.pdf}},
%  year = 2014
% }

% @article{Alpher02,
% author = {FirstName Alpher},
% title = {Frobnication},
% journal = {Journal of Foo},
% volume = 12, 
% number = 1, 
% pages = {234--778}, 
% year = 2002
% }

% @article{Alpher03,
% author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
% title = {Frobnication revisited},
% journal = {Journal of Foo},
% volume = 13, 
% number = 1, 
% pages = {234--778}, 
% year = 2003
% }

% @article{Alpher04,
% author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
% title = {Can a machine frobnicate?},
% journal = {Journal of Foo},
% volume = 14, 
% number = 1, 
% pages = {234--778}, 
% year = 2004
% }

@misc{TDS20,
 author = {Towards Data Science},
 title = {Adding Custom Layers on Top of a Hugging Face Model},
 note = {Available at: \url{https://towardsdatascience.com/adding-custom-layers-on-top-of-a-hugging-face-model-f1ccdfc257bd}},
 year = 2020
}


@misc{scienceqapaper,
      title={Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering}, 
      author={Pan Lu and Swaroop Mishra and Tony Xia and Liang Qiu and Kai-Wei Chang and Song-Chun Zhu and Oyvind Tafjord and Peter Clark and Ashwin Kalyan},
      year={2022},
      eprint={2209.09513},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{MultipleChoice,
 author = {Hugging Face},
 title = {Multiple Choice},
 note = {Available at: \url{https://huggingface.co/docs/transformers/tasks/multiple_choice}},
}

@misc{HuggingFaceDocsDQA,
 author = {Hugging Face},
 title = {Document Question Answering},
 note = {Available at: \url{https://huggingface.co/docs/transformers/tasks/document_question_answering}},
}

@misc{abdokamr_2021, 
    title={Question answering with T5}, 
    url={https://www.kaggle.com/code/abdokamr/question-answering-with-t5}, 
    journal={Kaggle}, 
    publisher={Kaggle}, 
    author={Abdokamr}, 
    year={2021}, 
    month={Aug}
} 

@misc{Li19,
 author = {Li, Liunian Harold and Mark, Yatskar and Da, Chen and Hessel, Matt and Radev, Dragomir},
 title = {VisualBERT: A Simple and Performant Baseline for Vision and Language},
 note = {Available at: \url{https://arxiv.org/pdf/1908.03557.pdf}},
 year = 2019
}

@misc{Lu19,
 author = {Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
 title = {VilBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},
 note = {Available at: \url{https://arxiv.org/pdf/1908.02265.pdf}},
 year = 2019
}

@misc{Singh19,
 author = {Singh, Amanpreet and Natarajan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, DSOTA23evi and Rohrbach, Marcus},
 title = {Towards VQA Models That Can Read},
 note = {Available at: \url{https://arxiv.org/pdf/1904.08920.pdf}},
 year = 2019
}

@misc{Kim21,
 author = {Kim, Wonjae and Lee, Kyung-Min and Lee, Jin-Hwa and Park, Chanho and Jang, Youngeun and Park, Seonguk and Yoon, Byeongchang and Hwang, Sung Ju},
 title = {ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision},
 note = {Available at: \url{https://arxiv.org/pdf/2102.03334.pdf}},
 year = 2021
}

@misc{Carion20,
 author = {Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
 title = {End-to-End Object Detection with Transformers},
 note = {Available at: \url{https://arxiv.org/pdf/2005.12872.pdf}},
 year = 2020
}

@misc{Liu19,
 author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
 title = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
 note = {Available at: \url{https://arxiv.org/pdf/1907.11692.pdf}},
 year = 2019
}

@misc{Sanh19,
 author = {Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
 title = {DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
 note = {Available at: \url{https://arxiv.org/pdf/1910.01108v4.pdf}},
 year = 2019
}

@misc{Khashabi20,
 author = {Khashabi, Daniel and Chaudhary, Tushar and Sen, Ayush and Chen, Jing and Choi, Yejin and Lapata, Mirella},
 title = {UNIFIEDQA: Crossing Format Boundaries with a Single QA System},
 note = {Available at: \url{https://aclanthology.org/2020.findings-emnlp.171.pdf}},
 year = 2020
}

@misc{Wei22,
 author = {Wei, Ji and Hao, Yixin and Bosselut, Antoine and Choi, Yejin},
 title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
 note = {Available at: \url{https://arxiv.org/pdf/2201.11903.pdf}},
 year = 2022
}

@misc{Talmor20,
 author = {Talmor, Alon and Herzig, Jonathan and Lourie, Nicholas and Berant, Jonathan},
 title = {Leap-Of-Thought: Teaching Pre-Trained Models to Systematically Reason Over Implicit Knowledge},
 note = {Available at: \url{https://arxiv.org/pdf/2006.06609.pdf}},
 year = 2020
}

@misc{Wang17,
 author = {Wang, Pengcheng and Abbeel, Pieter},
 title = {Program Induction by Rationale Generation},
 note = {Available at: \url{https://aclanthology.org/P17-1015.pdf}},
 year = 2017
}

@misc{SOTA23,
      title={Multimodal Chain-of-Thought Reasoning in Language Models}, 
      author={Zhuosheng Zhang and Aston Zhang and Mu Li and Hai Zhao and George Karypis and Alex Smola},
      year={2023},
      eprint={2302.00923},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{TextVQA,
 author = {Text VQA},
 title = {Text VQA: A dataset for reasoning about text in images},
 note = {Available at: \url{https://textvqa.org/}},
}

@misc{ScienceQA,
 author = {ScienceQA},
 title = {ScienceQA: A multimodal multiple-choice science question dataset},
 note = {Available at: \url{https://scienceqa.github.io/}},
}


@misc{huggingface2020t5,
  title = {T5 Small Model},
  author = {Hugging Face},
  year = {2020},
  howpublished = {\url{https://huggingface.co/t5-small}}
}

@misc{huggingface2021vilt,
  title = {ViLT Model Documentation},
  author = {Hugging Face},
  year = {2021},
  howpublished = {\url{https://huggingface.co/docs/transformers/model_doc/vilt}}
}


@misc{huggingface2021vit,
  title = {Vision Transformer Model Documentation},
  author = {Hugging Face},
  year = {2021},
  howpublished = {\url{https://huggingface.co/docs/transformers/model_doc/vit}}
}

@misc{huggingface2019gpt2,
  title = {GPT-2 Model},
  author = {Hugging Face},
  year = {2019},
  howpublished = {\url{https://huggingface.co/gpt2}}
}

@misc{huggingface2020roberta,
  title = {RoBERTa Model Documentation},
  author = {Hugging Face},
  year = {2020},
  howpublished = {\url{https://huggingface.co/docs/transformers/model_doc/roberta}}
}

@misc{huggingface2020distilbert,
  title = {DistilBERT Model Documentation},
  author = {Hugging Face},
  year = {2020},
  howpublished = {\url{https://huggingface.co/docs/transformers/model_doc/distilbert}}
}

@misc{huggingface2021detr,
  title = {DETR Model Documentation},
  author = {Hugging Face},
  year = {2021},
  howpublished = {\url{https://huggingface.co/docs/transformers/model_doc/detr}}
}


@misc{huggingface2021textvqa,
  title = {TextVQA Dataset},
  author = {Hugging Face},
  year = {2021},
  howpublished = {\url{https://huggingface.co/datasets/textvqa}}
}

@misc{huggingface2022scienceqa,
  title = {ScienceQA Dataset},
  author = {Hugging Face},
  year = {2022},
  howpublished = {\url{https://huggingface.co/datasets/derek-thomas/ScienceQA}}
}

@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{huggingface2021vitgpt2,
  title = {ViT-GPT2 Image Captioning},
  author = {Hugging Face},
  year = {2021},
  howpublished = {\url{https://huggingface.co/nlpconnect/vit-gpt2-image-captioning}}
}

@misc{huggingface2021visualbert,
  title = {Visual BERT Model Documentation},
  author = {Hugging Face},
  year = {2021},
  howpublished = {\url{https://huggingface.co/docs/transformers/model_doc/visual_bert}}
}

