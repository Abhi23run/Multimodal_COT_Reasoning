{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXQ-Fm5-HvGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d080f5b-daf0-4322-c411-2ebe205ead74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.14.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68KJBOn2K9n1",
        "outputId": "f133768b-3b81-4b0c-81a9-88550b93fd43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoTokenizer\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "torch.backends.cuda.max_split_size_mb = 1024\n",
        "# Check if a GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define the model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)"
      ],
      "metadata": {
        "id": "AbBvrE2hI0p1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"derek-thomas/ScienceQA\")\n",
        "train_data, val_data = dataset[\"train\"], dataset[\"validation\"]"
      ],
      "metadata": {
        "id": "Mj1QhzdoI3Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir scienceqa_data"
      ],
      "metadata": {
        "id": "NUn94wkErjER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "vit_model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vit_model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "max_length = 64\n",
        "num_beams = 4\n",
        "gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n",
        "def predict_step(example):\n",
        "  images = []\n",
        "  # for image_path in image_paths:\n",
        "  #   i_image = Image.open(image_path)\n",
        "  #   if i_image.mode != \"RGB\":\n",
        "  #     i_image = i_image.convert(mode=\"RGB\")\n",
        "  image = example[\"image\"]\n",
        "  if image:\n",
        "    images.append(image)\n",
        "\n",
        "    pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n",
        "    pixel_values = pixel_values.to(device)\n",
        "\n",
        "    output_ids = vit_model.generate(pixel_values, **gen_kwargs)\n",
        "\n",
        "    preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "\n",
        "    example[\"captions\"] = preds[0]\n",
        "  else:\n",
        "    example[\"captions\"] = \"\"\n",
        "  return example"
      ],
      "metadata": {
        "id": "OPfRVX35I-2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mapping the predict_step function to generate image captions for training set\n",
        "train_data_captions = train_data.map(predict_step)"
      ],
      "metadata": {
        "id": "F7p2GsuLJQN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample= val_data.to_dict()"
      ],
      "metadata": {
        "id": "cUCY5yXbRaGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample1 = val_data.train_test_split(test_size=0.05)[\"test\"]"
      ],
      "metadata": {
        "id": "ZqBHwH7h42Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sample1)"
      ],
      "metadata": {
        "id": "K3ayWX2D5L1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mapping the predict_step function to generate image captions for training set\n",
        "val_data_captions = sample1.map(predict_step)"
      ],
      "metadata": {
        "id": "ivGB77FYLg7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data_captions[4]"
      ],
      "metadata": {
        "id": "MbLHBLCf5Tbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data_captions)"
      ],
      "metadata": {
        "id": "-fr6HT7OZ9Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_captions_dict = train_data_captions.to_dict()"
      ],
      "metadata": {
        "id": "d9iX9uD3Z_aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_captions_dict.keys()"
      ],
      "metadata": {
        "id": "pNoomNnOaZvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import cPickle as pickle\n",
        "except ImportError:  # Python 3.x\n",
        "    import pickle\n",
        "\n",
        "# with open('./scienceqa_data/train_captionsdata.p', 'w') as fp:\n",
        "#     pickle.dump(train_data_captions_dict, fp, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "Z2aRSE9KY4J_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./scienceqa_data/train_captionsdata.pickle', 'wb') as handle:\n",
        "    pickle.dump(train_data_captions_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "ZBzHBfaea1kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./scienceqa_data/train_captionsdata.pickle', 'rb') as handle:\n",
        "    train_data_captions_dict = pickle.load(handle)"
      ],
      "metadata": {
        "id": "ipshijwSbKmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data_captions_dict)"
      ],
      "metadata": {
        "id": "WaOT_gT9ilbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_captions.keys()"
      ],
      "metadata": {
        "id": "Fmz1KUZ5inpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_captions_dict = train_data_captions.to_dict()"
      ],
      "metadata": {
        "id": "3zCWcsIL2Xxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data_captions_dict = val_data_captions.to_dict()"
      ],
      "metadata": {
        "id": "BXoHxsiRbdYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./scienceqa_data/valid_captionsdata.pickle', 'wb') as handle:\n",
        "    pickle.dump(val_data_captions_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "Xo4ogNiXbVfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./scienceqa_data/valid_captionsdata.pickle', 'rb') as handle:\n",
        "    val_data_captions_dict = pickle.load(handle)"
      ],
      "metadata": {
        "id": "P7ee4wY8bVb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data_captions_dict"
      ],
      "metadata": {
        "id": "RPJG1EGY1RIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "# with open(\"./scienceqa_data/valid_captionsdata.json\", 'w') as file:\n",
        "#     json.dump(val_data_captions_dict, file)"
      ],
      "metadata": {
        "id": "m9qmsFUfuMsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets"
      ],
      "metadata": {
        "id": "PyrKy-KdjjUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_captions = datasets.Dataset.from_pandas(pd.DataFrame(data=train_data_captions_dict))"
      ],
      "metadata": {
        "id": "71qwCYHpjGzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_captions[0]"
      ],
      "metadata": {
        "id": "S6v5gCxIjkx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data_captions = datasets.Dataset.from_pandas(pd.DataFrame(data=val_data_captions_dict))"
      ],
      "metadata": {
        "id": "M31vCikFjwzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data_captions[3]"
      ],
      "metadata": {
        "id": "v6ENUr0rj0VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device) \n",
        "#Change this to the new model from checkpoints."
      ],
      "metadata": {
        "id": "8Xxa0v9p6RFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
      ],
      "metadata": {
        "id": "CoEhDhQdeZWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# process the examples in input and target text format and the eos token at the end \n",
        "\n",
        "#For answer ONLY (not solution and explanation)\n",
        "def add_eos_to_examples(example):\n",
        "    example['input_text'] = 'question: %s  choices: %s  context: %s </s>' % (example['captions'].lower()+\". \"+example['question'].lower(), example['choices'], example['skill'].lower()+example['hint'].lower())\n",
        "    example['target_text'] = 'answer: %s </s>' % (example['choices'][example['answer']])\n",
        "    return example\n",
        "\n",
        "# tokenize the examples\n",
        "def convert_to_features(example_batch):\n",
        "    input_encodings = tokenizer.batch_encode_plus(example_batch['input_text'], pad_to_max_length=True, max_length=512, truncation=True)\n",
        "    target_encodings = tokenizer.batch_encode_plus(example_batch['target_text'], pad_to_max_length=True, max_length=128, truncation=True)\n",
        "    #max_length = 128 whej just answer, 256 when answer & explanation, 512 when all three\n",
        "    encodings = {\n",
        "        'input_ids': input_encodings['input_ids'], \n",
        "        'attention_mask': input_encodings['attention_mask'],\n",
        "        'target_ids': target_encodings['input_ids'],\n",
        "        'target_attention_mask': target_encodings['attention_mask']\n",
        "    }\n",
        "\n",
        "    return encodings"
      ],
      "metadata": {
        "id": "oOzZ5aHZMKT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# process the examples in input and target text format and the eos token at the end\n",
        "# Define the model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"./models_saved/t5small_answer_model2_512_128_10_8_8\").to(device) \n",
        "#Change this to the new model from checkpoints.\n",
        "\n",
        "#For answer and explanation\n",
        "def add_eos_to_examples(example):\n",
        "    example['input_text'] = 'question: %s  choices: %s  context: %s </s>' % (example['captions'].lower()+\". \"+example['question'].lower(), example['choices'], example['skill'].lower()+example['hint'].lower())\n",
        "    example['target_text'] = 'answer: %s  explanation: %s </s>' % (example['choices'][example['answer']], example[\"solution\"])\n",
        "    return example\n",
        "\n",
        "# tokenize the examples\n",
        "def convert_to_features(example_batch):\n",
        "    input_encodings = tokenizer.batch_encode_plus(example_batch['input_text'], pad_to_max_length=True, max_length=512, truncation=True)\n",
        "    target_encodings = tokenizer.batch_encode_plus(example_batch['target_text'], pad_to_max_length=True, max_length=256, truncation=True)\n",
        "    #max_length = 128 whej just answer, 256 when answer & explanation, 512 when all three\n",
        "    encodings = {\n",
        "        'input_ids': input_encodings['input_ids'], \n",
        "        'attention_mask': input_encodings['attention_mask'],\n",
        "        'target_ids': target_encodings['input_ids'],\n",
        "        'target_attention_mask': target_encodings['attention_mask']\n",
        "    }\n",
        "\n",
        "    return encodings"
      ],
      "metadata": {
        "id": "eEBcJ9xUhf9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# process the examples in input and target text format and the eos token at the end\n",
        "# Define the model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"./models_saved/t5small_answer_model2_512_128_10_8_8\").to(device) \n",
        "#Change this to the new model from checkpoints.\n",
        "\n",
        "#For answer with generated explanation in input\n",
        "def add_eos_to_examples(example):\n",
        "    example['input_text'] = 'question: %s  choices: %s  context: %s </s>' % (example['captions'].lower()+\". \"+example['question'].lower(), example['choices'], example['generated_exp']+example['hint'].lower())\n",
        "    example['target_text'] = 'answer: %s </s>' % (example['choices'][example['answer']])\n",
        "    return example\n",
        "\n",
        "# tokenize the examples\n",
        "def convert_to_features(example_batch):\n",
        "    input_encodings = tokenizer.batch_encode_plus(example_batch['input_text'], pad_to_max_length=True, max_length=512, truncation=True)\n",
        "    target_encodings = tokenizer.batch_encode_plus(example_batch['target_text'], pad_to_max_length=True, max_length=128, truncation=True)\n",
        "    #max_length = 128 whej just answer, 256 when answer & explanation, 512 when all three\n",
        "    encodings = {\n",
        "        'input_ids': input_encodings['input_ids'], \n",
        "        'attention_mask': input_encodings['attention_mask'],\n",
        "        'target_ids': target_encodings['input_ids'],\n",
        "        'target_attention_mask': target_encodings['attention_mask']\n",
        "    }\n",
        "\n",
        "    return encodings"
      ],
      "metadata": {
        "id": "rIk6txf4XrgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For generated examples as input:\n",
        "\n",
        "# map add_eos_to_examples function to the dataset example wise \n",
        "train_dataset = train_data_captions_gen_exp.map(add_eos_to_examples, load_from_cache_file=False)\n",
        "# map convert_to_features batch wise\n",
        "train_dataset = train_dataset.map(convert_to_features, batched=True)\n",
        "\n",
        "valid_dataset = val_data_captions_gen_exp.map(add_eos_to_examples, load_from_cache_file=False)\n",
        "valid_dataset = valid_dataset.map(convert_to_features, batched=True, load_from_cache_file=False)\n",
        "\n",
        "\n",
        "# set the tensor type and the columns which the dataset should return\n",
        "columns = ['input_ids', 'target_ids', 'attention_mask', 'target_attention_mask']\n",
        "train_dataset.set_format(type='torch', columns=columns)\n",
        "valid_dataset.set_format(type='torch', columns=columns)"
      ],
      "metadata": {
        "id": "AbhXH9zUdaoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map add_eos_to_examples function to the dataset example wise \n",
        "train_dataset = train_data_captions.map(add_eos_to_examples, load_from_cache_file=False)\n",
        "# map convert_to_features batch wise\n",
        "train_dataset = train_dataset.map(convert_to_features, batched=True)\n",
        "\n",
        "valid_dataset = val_data_captions.map(add_eos_to_examples, load_from_cache_file=False)\n",
        "valid_dataset = valid_dataset.map(convert_to_features, batched=True, load_from_cache_file=False)\n",
        "\n",
        "\n",
        "# set the tensor type and the columns which the dataset should return\n",
        "columns = ['input_ids', 'target_ids', 'attention_mask', 'target_attention_mask']\n",
        "train_dataset.set_format(type='torch', columns=columns)\n",
        "valid_dataset.set_format(type='torch', columns=columns)"
      ],
      "metadata": {
        "id": "uXfsJw9wJGhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset), len(valid_dataset)"
      ],
      "metadata": {
        "id": "THx2a-sGfD5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=8)"
      ],
      "metadata": {
        "id": "9I7LlKCVfF1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "print(batch.keys())"
      ],
      "metadata": {
        "id": "mpDTvgomfIhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(batch['input_ids'][7])"
      ],
      "metadata": {
        "id": "6qI7OBerfJlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(batch['target_ids'][7])"
      ],
      "metadata": {
        "id": "4ECHwwNMfMhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollator, AdamW, get_linear_schedule_with_warmup\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ZKmB7O3Yf2sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_collator(batch):\n",
        "    input_ids = torch.stack([example['input_ids'] for example in batch])\n",
        "    attention_mask = torch.stack([example['attention_mask'] for example in batch])\n",
        "\n",
        "    target_ids = torch.stack([example['target_ids'] for example in batch])\n",
        "    target_attention_mask = torch.stack([example['target_attention_mask'] for example in batch])\n",
        "    \n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask,\n",
        "        'target_ids': target_ids,\n",
        "        'target_attention_mask': target_attention_mask\n",
        "    }"
      ],
      "metadata": {
        "id": "aw8i87GygBzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "num_training_steps = 10000\n",
        "num_warmup_steps = 500\n",
        "lr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n",
        "\n",
        "# Define the training loop\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "for epoch in range(10):\n",
        "    print(\"Training: \")\n",
        "    model.train(True)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=data_collator)\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(train_dataloader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        target_ids = batch['target_ids'].to(device)\n",
        "        target_attention_mask = batch['target_attention_mask'].to(device)\n",
        "        \n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=target_ids,\n",
        "            decoder_attention_mask=target_attention_mask,\n",
        "            use_cache=False\n",
        "        )\n",
        "        \n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        total_loss += loss.item()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "    train_epoch_loss = total_loss / len(train_dataloader) \n",
        "    train_loss.append(train_epoch_loss)\n",
        "    print(f\"Training Loss at epoch {epoch}: {train_epoch_loss}\")\n",
        "\n",
        "    print(\"Validation:\")\n",
        "    valid_dataloader = DataLoader(valid_dataset, batch_size=8, shuffle=False, collate_fn=data_collator)\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(valid_dataloader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            target_ids = batch['target_ids'].to(device)\n",
        "            target_attention_mask = batch['target_attention_mask'].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=target_ids,\n",
        "                decoder_attention_mask=target_attention_mask,\n",
        "                use_cache=False\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "    val_epoch_loss = total_loss / len(valid_dataloader) \n",
        "    val_loss.append(val_epoch_loss)\n",
        "    print(f\"Validation Loss at epoch {epoch}: {val_epoch_loss}\")\n",
        "    # val_loss.append(total_loss / len(valid_dataloader))\n",
        "    # print(val_loss)\n"
      ],
      "metadata": {
        "id": "2Yus6XUSgEgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot the training and validation losses\n",
        "plt.plot(train_loss[0:6], label='Train Loss')\n",
        "plt.plot(val_loss[0:6], label='Valid Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title(\"Training and Validation Loss for Answer with Generated Explanation as Input (5 Epochs)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eTiGNOV0mwEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot the training and validation losses\n",
        "plt.plot(train_loss[1:], label='Train Loss')\n",
        "plt.plot(val_loss[1:], label='Valid Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title(\"Training and Validation Loss for Answer with Generated Explanation as Input\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lwQEUOsj6o7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./scienceqa_data/train_loss_model2', 'wb') as handle:\n",
        "    pickle.dump(train_loss, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "RAMhUwp6vxYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./scienceqa_data/val_loss_model2', 'wb') as handle:\n",
        "    pickle.dump(val_loss, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "yI5OGgbsXeh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.parameters()"
      ],
      "metadata": {
        "id": "KIlWmInOgshn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %mkdir models_saved"
      ],
      "metadata": {
        "id": "zDGN5duZEmuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 6 Plots"
      ],
      "metadata": {
        "id": "ML2_Mkq24LI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot the training and validation losses\n",
        "plt.plot(train_loss[0:6], label='Train Loss')\n",
        "plt.plot(val_loss[0:6], label='Valid Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title(\"Training and Validation Loss for Pre-trained T5 Small for Answer and Explanation Generation (5 Epochs)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bMnCkNkEdIV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot the training and validation losses\n",
        "plt.plot(train_loss, label='Train Loss')\n",
        "plt.plot(val_loss, label='Valid Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title(\"Training and Validation Loss for Pre-trained T5 Small for Answer and Explanation Generation\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ya1XwKxPdFTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./scienceqa_data/train_loss_model6', 'wb') as handle:\n",
        "    pickle.dump(train_loss, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "vlRAiErr4M_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./scienceqa_data/val_loss_model6', 'wb') as handle:\n",
        "    pickle.dump(val_loss, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "Ys79LtLY4QVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the model parameters for model checkpoint saving"
      ],
      "metadata": {
        "id": "cPSENeaobaB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters for answer only model\n",
        "input_max_len = 512\n",
        "target_max_len = 128\n",
        "num_epochs = 10\n",
        "# learning_rate = 1e-5\n",
        "train_batch_size = 8\n",
        "val_batch_size = 8\n",
        "# no_of_training_steps = 10000\n",
        "# no_of_warmup_steps = 500\n",
        "model_name = f\"t5small_answer_model14_{input_max_len}_{target_max_len}_{num_epochs}_{train_batch_size}_{val_batch_size}\""
      ],
      "metadata": {
        "id": "30LRzO2-JHf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name"
      ],
      "metadata": {
        "id": "yAZOY2ahJIOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Answer only model\n",
        "model.save_pretrained(f\"./models_saved/{model_name}\", from_pt=True)"
      ],
      "metadata": {
        "id": "kGgkQkZZqatB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H_4WMLkRdyVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZXuSFJ0nasRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "cv_LZZzsHnCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from rouge_score import rouge_scorer\n",
        "import string\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True, tokenizer=tokenizer)\n",
        "smoothie = SmoothingFunction().method4\n",
        "\n",
        "model.eval()\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, collate_fn=data_collator)\n",
        "\n",
        "model_answers_train = []\n",
        "target_answers_train = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(train_dataloader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        target_ids = batch['target_ids'].to(device)\n",
        "        target_attention_mask = batch['target_attention_mask'].to(device)\n",
        "        \n",
        "        outputs = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            # decoder_attention_mask=target_attention_mask,\n",
        "            max_length=512,\n",
        "            num_beams=10,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        \n",
        "        # Convert the generated output to text\n",
        "        output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "        target_text = tokenizer.batch_decode(target_ids, skip_special_tokens=True)\n",
        "        # print(output_text)\n",
        "        # print(\"--\")\n",
        "        # print(target_text)\n",
        "        model_answers_train.append(output_text)\n",
        "        target_answers_train.append(target_text)"
      ],
      "metadata": {
        "id": "WmiDmP6zgMjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_answers_train"
      ],
      "metadata": {
        "id": "WIMPRxtz73oU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_answers_train"
      ],
      "metadata": {
        "id": "Vk2sGk_k8AFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xr0hFOy08NiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %mkdir results"
      ],
      "metadata": {
        "id": "2FR7X1J4LbKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./results/model2_answers_train', 'wb') as handle:\n",
        "    pickle.dump(model_answers_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('./results/model2_target_answers_train', 'wb') as handle:\n",
        "    pickle.dump(target_answers_train, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "_LvroLNDhEBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./results/model6_answers_train', 'wb') as handle:\n",
        "    pickle.dump(model_answers_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('./results/model6_target_answers_train', 'wb') as handle:\n",
        "    pickle.dump(target_answers_train, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "RrJTA_LCZoYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./results/model14_answers_train', 'wb') as handle:\n",
        "    pickle.dump(model_answers_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('./results/model14_target_answers_train', 'wb') as handle:\n",
        "    pickle.dump(target_answers_train, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "0cKkkl7ibiPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics on Training Set"
      ],
      "metadata": {
        "id": "fVZaIFd_ZpEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_answers_train_overall,target_answers_train_overall=sum(model_answers_train,[]),sum(target_answers_train,[])"
      ],
      "metadata": {
        "id": "UF5gscqnLlYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_boolean_train=[a.lower().split(\"explanation:\")[0].strip()==b.lower().split(\"explanation:\")[0].strip() for a,b in zip((model_answers_train_overall),(target_answers_train_overall))]"
      ],
      "metadata": {
        "id": "Br8CBPRGXb0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_train=(sum(accuracy_boolean_train)/len(accuracy_boolean_train))*100\n",
        "print(f\"The training accuracy of the model is {acc_train:.2f} %\")"
      ],
      "metadata": {
        "id": "wS7ds4m1Ylcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp_bleu_score_train = []\n",
        "exp_precision_rouge1_score_train = []\n",
        "exp_recall_rouge1_score_train = []\n",
        "exp_precision_rouge2_score_train = []\n",
        "exp_recall_rouge2_score_train = []\n",
        "exp_precision_rougeL_score_train = []\n",
        "exp_recall_rougeL_score_train = []"
      ],
      "metadata": {
        "id": "iW5jZSkpZtGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(model_output,target_output):\n",
        "    out_exp,tar_exp=model_output.split(\"explanation:\")[1].strip(),target_output.split(\"explanation:\")[1].strip()\n",
        "    exp_bleu_score_train.append(sentence_bleu(tar_exp.split(), out_exp.split(), smoothing_function=smoothie))\n",
        "    exp_recall_rouge1_score_train.append(scorer.score(tar_exp, out_exp)['rouge1'][1])\n",
        "    exp_precision_rouge1_score_train.append(scorer.score(tar_exp, out_exp)['rouge1'][0])\n",
        "    exp_recall_rouge2_score_train.append(scorer.score(tar_exp, out_exp)['rouge2'][1])\n",
        "    exp_precision_rouge2_score_train.append(scorer.score(tar_exp, out_exp)['rouge2'][0])\n",
        "    exp_recall_rougeL_score_train.append(scorer.score(tar_exp, out_exp)['rougeL'][1])\n",
        "    exp_precision_rougeL_score_train.append(scorer.score(tar_exp, out_exp)['rougeL'][0])\n",
        "    return"
      ],
      "metadata": {
        "id": "gxTytuD9NLoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a,b in zip(model_answers_train_overall,target_answers_train_overall):  \n",
        "    try:\n",
        "        compute_metrics(a,b)\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "s3Qu4QdRNVzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Metrics:\")\n",
        "print(\"--\")\n",
        "print(\"For Explanation: \")\n",
        "print(f\"Bleu Score: {np.array(exp_bleu_score_train).mean()}\")\n",
        "print(f\"Rouge-1 Precision Score: {np.array(exp_precision_rouge1_score_train).mean()}\")\n",
        "print(f\"Rouge-1 Recall Score: {np.array(exp_recall_rouge1_score_train).mean()}\")\n",
        "print(f\"Rouge-2 Precision Score: {np.array(exp_precision_rouge2_score_train).mean()}\")\n",
        "print(f\"Rouge-2 Recall Score: {np.array(exp_recall_rouge2_score_train).mean()}\")\n",
        "print(f\"Rouge-L Precision Score: {np.array(exp_precision_rougeL_score_train).mean()}\")\n",
        "print(f\"Rouge-L Recall Score: {np.array(exp_recall_rougeL_score_train).mean()}\")\n"
      ],
      "metadata": {
        "id": "z9LXJKrwN41k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_captions_gen_exp_dict = train_data_captions_dict"
      ],
      "metadata": {
        "id": "mzY0PSduZd-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data_captions_gen_exp_dict[\"question\"])"
      ],
      "metadata": {
        "id": "km_QiafIaGPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_exp_train = [i.lower().split(\"explanation:\")[1].strip() if \"explanation:\" in i.lower() else '' for i in model_answers_train_overall ]\n",
        "train_data_captions_gen_exp_dict[\"generated_exp\"] = gen_exp_train\n",
        "train_data_captions_gen_exp = datasets.Dataset.from_pandas(pd.DataFrame(data=train_data_captions_gen_exp_dict))"
      ],
      "metadata": {
        "id": "rO8106ImaOvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data_captions_gen_exp_dict = val_data_captions_dict\n",
        "gen_exp_val = [i.lower().split(\"explanation:\")[1].strip() if \"explanation:\" in i.lower() else '' for i in model_answers_overall ]\n",
        "val_data_captions_gen_exp_dict[\"generated_exp\"] = gen_exp_val\n",
        "val_data_captions_gen_exp = datasets.Dataset.from_pandas(pd.DataFrame(data=val_data_captions_gen_exp_dict))"
      ],
      "metadata": {
        "id": "IXQg6ua9c4qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model generation for validation dataset"
      ],
      "metadata": {
        "id": "QPSwR1yGNpiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from rouge_score import rouge_scorer\n",
        "import string\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True, tokenizer=tokenizer)\n",
        "smoothie = SmoothingFunction().method4\n",
        "\n",
        "model.eval()\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=8, collate_fn=data_collator)\n",
        "\n",
        "model_answers = []\n",
        "target_answers = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(valid_dataloader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        target_ids = batch['target_ids'].to(device)\n",
        "        target_attention_mask = batch['target_attention_mask'].to(device)\n",
        "        \n",
        "        outputs = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            # decoder_attention_mask=target_attention_mask,\n",
        "            max_length=512,\n",
        "            num_beams=10,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        \n",
        "        # Convert the generated output to text\n",
        "        output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "        target_text = tokenizer.batch_decode(target_ids, skip_special_tokens=True)\n",
        "        model_answers.append(output_text)\n",
        "        target_answers.append(target_text)"
      ],
      "metadata": {
        "id": "8H6NXvkl94s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./results/model_2_model_answers', 'wb') as handle:\n",
        "    pickle.dump(model_answers, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('./results/model_2_target_answers', 'wb') as handle:\n",
        "    pickle.dump(target_answers, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "EUwS_W-GhFCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./results/model6_valid_model_answers', 'wb') as handle:\n",
        "    pickle.dump(model_answers, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('./results/model6_valid_target_answers', 'wb') as handle:\n",
        "    pickle.dump(target_answers, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "Ng7CthY557XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./results/model14_valid_model_answers', 'wb') as handle:\n",
        "    pickle.dump(model_answers, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('./results/model14_valid_target_answers', 'wb') as handle:\n",
        "    pickle.dump(target_answers, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "0X3DffTOkM-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics on Validation Set"
      ],
      "metadata": {
        "id": "MYohok1AZ7P_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_answers_overall,target_answers_overall=sum(model_answers,[]),sum(target_answers,[])\n",
        "\n",
        "accuracy_boolean_valid = [a.lower().split(\"explanation:\")[0].strip()==b.lower().split(\"explanation:\")[0].strip() for a,b in zip((model_answers_overall),(target_answers_overall))]"
      ],
      "metadata": {
        "id": "rmUfzhGzVY7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_train=(sum(accuracy_boolean_valid)/len(accuracy_boolean_valid))*100\n",
        "print(f\"The validation accuracy of the model is {acc_train:.2f} %\")"
      ],
      "metadata": {
        "id": "YapicmfmaFTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp_bleu_score_valid = []\n",
        "exp_precision_rouge1_score_valid = []\n",
        "exp_recall_rouge1_score_valid = []\n",
        "exp_precision_rouge2_score_valid = []\n",
        "exp_recall_rouge2_score_valid = []\n",
        "exp_precision_rougeL_score_valid = []\n",
        "exp_recall_rougeL_score_valid = []"
      ],
      "metadata": {
        "id": "epbYY1yBaNPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(model_output,target_output):\n",
        "    out_exp,tar_exp=model_output.split(\"explanation:\")[1].strip(),target_output.split(\"explanation:\")[1].strip()\n",
        "    exp_bleu_score_valid.append(sentence_bleu(tar_exp.split(), out_exp.split(), smoothing_function=smoothie))\n",
        "    exp_recall_rouge1_score_valid.append(scorer.score(tar_exp, out_exp)['rouge1'][1])\n",
        "    exp_precision_rouge1_score_valid.append(scorer.score(tar_exp, out_exp)['rouge1'][0])\n",
        "    exp_recall_rouge2_score_valid.append(scorer.score(tar_exp, out_exp)['rouge2'][1])\n",
        "    exp_precision_rouge2_score_valid.append(scorer.score(tar_exp, out_exp)['rouge2'][0])\n",
        "    exp_recall_rougeL_score_valid.append(scorer.score(tar_exp, out_exp)['rougeL'][1])\n",
        "    exp_precision_rougeL_score_valid.append(scorer.score(tar_exp, out_exp)['rougeL'][0])\n",
        "    return"
      ],
      "metadata": {
        "id": "E1H-MIiCaNLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a,b in zip(model_answers_overall,target_answers_overall):  \n",
        "    try:\n",
        "        compute_metrics(a,b)\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "5TcOOLstQA-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Validation Metrics:\")\n",
        "print(\"--\")\n",
        "print(\"For Explanation: \")\n",
        "print(f\"Bleu Score: {np.array(exp_bleu_score_valid).mean()}\")\n",
        "print(f\"Rouge-1 Precision Score: {np.array(exp_precision_rouge1_score_valid).mean()}\")\n",
        "print(f\"Rouge-1 Recall Score: {np.array(exp_recall_rouge1_score_valid).mean()}\")\n",
        "print(f\"Rouge-2 Precision Score: {np.array(exp_precision_rouge2_score_valid).mean()}\")\n",
        "print(f\"Rouge-2 Recall Score: {np.array(exp_recall_rouge2_score_valid).mean()}\")\n",
        "print(f\"Rouge-L Precision Score: {np.array(exp_precision_rougeL_score_valid).mean()}\")\n",
        "print(f\"Rouge-L Recall Score: {np.array(exp_recall_rougeL_score_valid).mean()}\")\n"
      ],
      "metadata": {
        "id": "AtAGlBRDQE3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PPtLL9VqV_fn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}